{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<figure class=\"half\" style=\"display:flex\">\n",
    "    <img src=\"./imag/ZARA.PNG\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<figure class=\"half\" style=\"display:flex\">\n",
    "    <img src=\"./imag/keras.PNG\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## *IMPORTACIÃ“N DE LIBRERIAS*\n",
    "from IPython.display import display, HTML\n",
    "HTML('<style>.output {flex-direction: row;}</style>')\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<figure class=\"half\" style=\"display:flex\">\n",
    "    <img src=\"./imag/JEANS.jpg\" width=\"350\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rocio\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Predicted: [('n03594734', 'jean', 0.80945915), ('n02808304', 'bath_towel', 0.05522593), ('n03877472', 'pajama', 0.03028701)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'JEANS.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<figure class=\"half\" style=\"display:flex\">\n",
    "    <img src=\"./imag/ABRIGO BE.jpg\" width=\"350\">\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n03404251', 'fur_coat', 0.7052111), ('n04479046', 'trench_coat', 0.12823585), ('n03770439', 'miniskirt', 0.045553934)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'ABRIGO 2.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<figure class=\"half\" style=\"display:flex\">\n",
    "    <img src=\"./imag/BLAZER 1.jpg\" width=\"350\">\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n04479046', 'trench_coat', 0.9753817), ('n04350905', 'suit', 0.013957926), ('n03404251', 'fur_coat', 0.0077237664)]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'TRENCH.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
